# Machine Learning Model Data

The file `security_dataset.csv` is a dataset generated by the system using the `generate_dataset` function in `src/data_generator.py`. This function uses the CLIPS-based `SecurityExpertSystem` to evaluate randomly generated security metrics.

The CSV file contains rows where each row represents a system's security profile. The columns are:

- **Input Features**: These are the security metrics collected from a system:
  - `patch_status`, `patch_hotfixes_count`
  - `ports_count`
  - `services_total`, `services_running`, `services_stopped`
  - `firewall_domain`, `firewall_private`, `firewall_public`
  - `antivirus_count`, `antivirus_enabled`
  - `password_min_length`, `password_max_age`
- **Target Variables**: These are the outputs from the expert system's evaluation of the input features:
  - `target_score`: An integer score from 0-100.
  - `target_grade`: A categorical grade (e.g., "Excellent", "Good", "Poor", "Critical Risk").

**How it helps a PyTorch ML model learn the expert system:**

This dataset is designed for **supervised learning**. A PyTorch ML model can learn the relationship between the input security metrics and the expert system's `target_score` and `target_grade`.

1. **Training Data**: The input features serve as the `X` (inputs) and the target variables as the `y` (outputs or labels) for the model.
2. **Learning by Example**: By processing many examples from this CSV, the model learns the patterns and rules implicitly encoded in the expert system. For instance, it learns how an "out-of-date" `patch_status` and "OFF" `firewall_public` status typically lead to a lower `target_score` and a "Poor" or "Critical Risk" `target_grade`.
3. **Mimicking Behavior**:
   - To predict the `target_score`, a **regression model** can be trained.
   - To predict the `target_grade`, a **classification model** can be trained.
4. **Accuracy**: The accuracy of the ML model in mimicking the expert system will depend on the size and diversity of the dataset, the complexity of the model, and the training process. A larger and more representative dataset (like the one in security_dataset.csv) allows the model to learn a more nuanced and accurate approximation of the expert system's decision-making process.

In essence, the security_dataset.csv provides the "ground truth" (as defined by the expert system) that a PyTorch model can use to learn and then replicate the security evaluation process.

## Using for PyTorch Training

```python
import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Load dataset
df = pd.read_csv('security_dataset.csv')

# Prepare features
feature_cols = [col for col in df.columns if not col.startswith('target_')]
X = df[feature_cols]

# Prepare targets
y_score = df['target_score']  # For regression
y_grade = LabelEncoder().fit_transform(df['target_grade'])  # For classification
```
